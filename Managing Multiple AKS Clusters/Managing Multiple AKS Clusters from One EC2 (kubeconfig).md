# ğŸ§  Managing Multiple AKS Clusters from One EC2 (kubeconfig)

---

## ğŸ§  How This Works (Important Concept)

ğŸ”‘ **kubeconfig is NOT one cluster**

- `kubeconfig` is just a **configuration file**
- It can contain **many clusters**, **many users**, and **many contexts**

ğŸ‘‰ **One EC2 VM**
ğŸ‘‰ **One `~/.kube/config` file**
ğŸ‘‰ **Multiple AKS clusters inside it**

---

## ğŸ—ï¸ Architecture (Very Common)

```
EC2 VM (kubectl installed)
â”‚
â”œâ”€â”€ ~/.kube/config
â”‚   â”œâ”€â”€ nakodtech-dev-cluster
â”‚   â”œâ”€â”€ nakodtech-prod-cluster
â”‚
â””â”€â”€ kubectl â†’ manages BOTH clusters
```

âœ… This is how **CI/CD agents**, **jump servers**, and **bastion hosts** work in real-world DevOps.

---

## â• How to Add BOTH AKS Clusters (From EC2)

### 1ï¸âƒ£ Login to Azure (Headless VM)

âš ï¸ On EC2 (no browser), normal `az login` will fail.

âœ… **Correct command**

```bash
az login --use-device-code
```

You will see something like:

```
To sign in, use a web browser to open https://microsoft.com/devicelogin
and enter the code: ABCD-EFGH
```

ğŸ‘‰ Open the link on your **laptop or phone**
ğŸ‘‰ Enter the code
ğŸ‘‰ Login to Azure

âœ” EC2 gets authenticated
âœ” Token stored locally
âœ” Ready to manage AKS

---

### 2ï¸âƒ£ Get kubeconfig for DEV cluster

```bash
az aks get-credentials \
  --resource-group rg-1 \
  --name nakodtech-dev-cluster
```

---

### 3ï¸âƒ£ Get kubeconfig for PROD cluster

```bash
az aks get-credentials \
  --resource-group rg-2 \
  --name nakodtech-prod-cluster
```

---

### âœ… Result

Azure **automatically merges** both clusters into:

```
~/.kube/config
```

âœ” No overwrite
âœ” No conflict
âœ” Multiple contexts created

_(Unless clusters share the same name)_

---

## ğŸ” Switching Between Clusters

### ğŸ“‹ List all contexts

```bash
kubectl config get-contexts
```

### ğŸ”„ Use DEV cluster

```bash
kubectl config use-context nakodtech-dev-cluster
```

### ğŸ”„ Use PROD cluster

```bash
kubectl config use-context nakodtech-prod-cluster
```

---

## ğŸ” Security Notes (Very Important)

Your **EC2 VM**:

âœ” Stores **certs / tokens only**
âœ” Communicates with AKS API servers via **HTTPS (443)**
âŒ Does **NOT** host Kubernetes

ğŸ‘‰ This setup is **safe**, **secure**, and **industry standard**.

---

## âš ï¸ Common Mistakes to Avoid

âŒ Thinking `kubeconfig = one cluster`
âŒ Overwriting kubeconfig manually
âŒ Using same cluster names in different resource groups
âŒ Using admin credentials in CI/CD pipelines

---

## â­ Best Practice (What Professionals Do)

âœ” One **bastion / jump EC2 VM**
âœ” Install:

- `kubectl`
- `helm`
- `terraform`
- `az cli`

âœ” Merge multiple kubeconfigs
âœ” Switch contexts when needed

ğŸ‘‰ This is exactly what you are implementing ğŸ‘

---

## ğŸ”¥ Bonus: Pro & Clean Setup (Optional)

Use **separate kubeconfig files**:

```bash
export KUBECONFIG=~/.kube/aks-dev:~/.kube/aks-prod
```

Then:

```bash
kubectl config get-contexts
```

âœ” Cleaner setup
âœ” Safer operations
âœ” Easy rollback

---

## âœ… Final Summary

âœ… One EC2 VM can manage **multiple AKS clusters**
âœ… Single kubeconfig location is **normal**
âœ… Device-code login is **expected on EC2**
âœ… This approach is **DevOps best practice** ğŸš€
